{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-ai-inference in c:\\dev\\azure-ai-search-python-playground\\.venv\\lib\\site-packages (1.0.0b5)\n",
      "Collecting firecrawl\n",
      "  Downloading firecrawl-1.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: isodate>=0.6.1 in c:\\dev\\azure-ai-search-python-playground\\.venv\\lib\\site-packages (from azure-ai-inference) (0.6.1)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in c:\\dev\\azure-ai-search-python-playground\\.venv\\lib\\site-packages (from azure-ai-inference) (1.31.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\dev\\azure-ai-search-python-playground\\.venv\\lib\\site-packages (from azure-ai-inference) (4.12.2)\n",
      "Requirement already satisfied: requests in c:\\dev\\azure-ai-search-python-playground\\.venv\\lib\\site-packages (from firecrawl) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\dev\\azure-ai-search-python-playground\\.venv\\lib\\site-packages (from firecrawl) (1.0.1)\n",
      "Requirement already satisfied: websockets in c:\\dev\\azure-ai-search-python-playground\\.venv\\lib\\site-packages (from firecrawl) (13.0.1)\n",
      "Requirement already satisfied: nest-asyncio in c:\\dev\\azure-ai-search-python-playground\\.venv\\lib\\site-packages (from firecrawl) (1.6.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\dev\\azure-ai-search-python-playground\\.venv\\lib\\site-packages (from azure-core>=1.30.0->azure-ai-inference) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\dev\\azure-ai-search-python-playground\\.venv\\lib\\site-packages (from requests->firecrawl) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\dev\\azure-ai-search-python-playground\\.venv\\lib\\site-packages (from requests->firecrawl) (3.9)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\dev\\azure-ai-search-python-playground\\.venv\\lib\\site-packages (from requests->firecrawl) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\dev\\azure-ai-search-python-playground\\.venv\\lib\\site-packages (from requests->firecrawl) (2024.8.30)\n",
      "Downloading firecrawl-1.4.0-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: firecrawl\n",
      "Successfully installed firecrawl-1.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-ai-inference firecrawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There are 5,280 feet in a mile.\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import os\n",
    "\n",
    "client = ChatCompletionsClient(endpoint=\"https://Phi-3-5-vision-instruct-pzimz.swedencentral.models.ai.azure.com/v1\", credential=AzureKeyCredential(\"DVUbvLfbduAwllELGCFfus1HnzgjNYfN\"))\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "        UserMessage(content=\"How many feet are in a mile?\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image presents a scatter plot analyzing the relationship between the quality and size of small language models (SLMs). Here are some observations:\n",
      "\n",
      "1. **Axes Description**:\n",
      "   - The vertical axis represents \"Quality,\" measured on the Massive Multitask Language Understanding (MMLU) benchmark.\n",
      "   - The horizontal axis represents the \"Size\" of the models in billions of parameters.\n",
      "\n",
      "2. **General Trends**:\n",
      "   - There appears to be a positive correlation between the size of the models and their quality. Larger models tend to achieve higher quality scores.\n",
      "   - However, there are notable exceptions, suggesting that size alone does not guarantee quality.\n",
      "\n",
      "3. **Model Distribution**:\n",
      "   - The models labeled as \"Phi-3-small,\" \"Phi-3-medium,\" \"Gemma 7B,\" and others are plotted at varying points, indicating differing quality and sizes.\n",
      "   - The \"Phi-3-small\" and \"Phi-3-medium\" models exhibit quality levels above average despite their smaller sizes compared to some others.\n",
      "\n",
      "4. **Clustering**:\n",
      "   - Models like \"Mistral 7B\" and \"Gemma 7B\" cluster in a range that indicates moderate quality with a size around 7 billion parameters.\n",
      "   - \"Mixtral 8x7B\" is plotted slightly higher in quality at a comparable size, suggesting efficacy in this configuration.\n",
      "\n",
      "5. **Outliers**:\n",
      "   - The \"Phi-3 mini-4k\" and \"Phi-3 mini-128k\" are notable outliers, showing lower quality scores despite their participation in the metric assessment, indicating possible limitations in smaller parameter configurations.\n",
      "\n",
      "6. **Implications**:\n",
      "   - This plot illustrates the complexity of developing effective language models, highlighting that while scaling up can improve performance, other factors may significantly influence quality. \n",
      "\n",
      "Overall, the data suggests a nuanced understanding of model design, advocating for careful consideration of both size and quality metrics in the development of small language models.\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from urllib.request import urlopen, Request\n",
    "import base64\n",
    "import IPython.display as Disp\n",
    "\n",
    "# Initialize Azure ChatCompletionsClient\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=\"https://fsunavala-openai-eus.openai.azure.com/openai/deployments/gpt-4o-mini\",\n",
    "    credential=AzureKeyCredential(\"a3f4bd3971e24bf1a6b09c83a98fb9eb\")\n",
    ")\n",
    "\n",
    "# Image URL (example image)\n",
    "image_url = \"https://news.microsoft.com/source/wp-content/uploads/2024/04/The-Phi-3-small-language-models-with-big-potential-1-1900x1069.jpg\"\n",
    "image_format = \"jpeg\"\n",
    "\n",
    "# Convert image to base64 format\n",
    "request = Request(image_url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "image_data = base64.b64encode(urlopen(request).read()).decode(\"utf-8\")\n",
    "data_url = f\"data:image/{image_format};base64,{image_data}\"\n",
    "\n",
    "# Display the image\n",
    "Disp.Image(url=image_url)\n",
    "\n",
    "# Create a chat completion request with both text and image\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        UserMessage(\n",
    "            content=[\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"What observations can be made about the following image?\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": data_url}\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the response content\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The image displays a scatter plot graph titled \"Quality vs Size in Small Language Models (SLMs)\" which compares the model quality of various small language models against their size, measured in billions of parameters (active). The x-axis represents the size of the model, and the y-axis represents the model quality. The graph includes several points representing different models such as Phi-3-small, Phi-3-mini-4k, Llama-3-88-In, and others. Each point is labeled with the model's name and some have additional labels like 'preview' or 'Medium'. The graph is designed to show a trend between the size of the model and its quality, with larger models generally appearing to have higher quality.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from urllib.request import urlopen, Request\n",
    "import base64\n",
    "import os\n",
    "import IPython.display as Disp\n",
    "\n",
    "# Initialize OpenAI client with your Azure Phi-3 endpoint and API key\n",
    "client = OpenAI(base_url=\"https://Phi-3-5-vision-instruct-pzimz.swedencentral.models.ai.azure.com/v1\", api_key=\"DVUbvLfbduAwllELGCFfus1HnzgjNYfN\")\n",
    "\n",
    "# Image URL (example image)\n",
    "image_url = \"https://news.microsoft.com/source/wp-content/uploads/2024/04/The-Phi-3-small-language-models-with-big-potential-1-1900x1069.jpg\"\n",
    "image_format = \"jpeg\"\n",
    "\n",
    "# Convert image to base64 format\n",
    "request = Request(image_url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "image_data = base64.b64encode(urlopen(request).read()).decode(\"utf-8\")\n",
    "data_url = f\"data:image/{image_format};base64,{image_data}\"\n",
    "\n",
    "# Display the image\n",
    "Disp.Image(url=image_url)\n",
    "\n",
    "# Prompt the Phi-3 model with text and the image data URL\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"What can you deduce from the following image?\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": data_url}}\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    model=\"azureai\",\n",
    "    max_tokens=2048\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(response.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
