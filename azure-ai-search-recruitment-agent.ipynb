{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ HR Resume Search using Assistant API File Search\n",
    "\n",
    "This notebook demonstrates how to use the OpenAI Assistant API's File Search capability\n",
    "to analyze resumes more effectively. The implementation follows best practices for\n",
    "file handling and annotation support.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Azure OpenAI resource with Assistant API access\n",
    "- Semantic Kernel v1.16+\n",
    "- Python 3.8+\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's install the required packages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install semantic-kernel==1.16.0 python-dotenv aiofiles nest_asyncio azure-search-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Import Dependencies and Configure Environment\n",
    " \n",
    "Let's import all necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from semantic_kernel.kernel import Kernel\n",
    "from semantic_kernel.agents.open_ai.azure_assistant_agent import AzureAssistantAgent\n",
    "from semantic_kernel.contents.chat_message_content import ChatMessageContent\n",
    "from semantic_kernel.contents.streaming_annotation_content import StreamingAnnotationContent\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Enable notebook async support\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Management\n",
    "\n",
    "We'll create a configuration class to manage our Azure OpenAI settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AzureConfig:\n",
    "    \"\"\"Configuration for Azure OpenAI Assistant.\"\"\"\n",
    "\n",
    "    api_key: str\n",
    "    endpoint: str\n",
    "    deployment_name: str\n",
    "    api_version: str = \"2024-10-01-preview\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_env(cls) -> \"AzureConfig\":\n",
    "        \"\"\"Load configuration from environment variables.\"\"\"\n",
    "        load_dotenv()\n",
    "\n",
    "        # Get environment variables\n",
    "        api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "        endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "        deployment_name = os.getenv(\"AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME\")\n",
    "\n",
    "        if not all([api_key, endpoint, deployment_name]):\n",
    "            missing = [\n",
    "                var\n",
    "                for var, val in {\n",
    "                    \"AZURE_OPENAI_API_KEY\": api_key,\n",
    "                    \"AZURE_OPENAI_ENDPOINT\": endpoint,\n",
    "                    \"AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME\": deployment_name,\n",
    "                }.items()\n",
    "                if not val\n",
    "            ]\n",
    "            raise ValueError(\n",
    "                f\"Missing required environment variables: {', '.join(missing)}\"\n",
    "            )\n",
    "\n",
    "        # Clean up endpoint URL\n",
    "        if endpoint:\n",
    "            endpoint = endpoint.rstrip(\"/\")\n",
    "\n",
    "        return cls(\n",
    "            api_key=api_key,\n",
    "            endpoint=endpoint,\n",
    "            deployment_name=deployment_name,\n",
    "            api_version=\"2024-10-01-preview\",\n",
    "        )\n",
    "\n",
    "    \"\"\"Configuration for Azure OpenAI Assistant.\"\"\"\n",
    "    api_key: str\n",
    "    endpoint: str\n",
    "    deployment_name: str\n",
    "    api_version: str = \"2024-10-01-preview\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_env(cls) -> \"AzureConfig\":\n",
    "        \"\"\"Load configuration from environment variables.\"\"\"\n",
    "        load_dotenv()\n",
    "\n",
    "        # Get environment variables\n",
    "        api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "        endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "        deployment_name = os.getenv(\"AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME\")\n",
    "        api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-10-01-preview\")\n",
    "\n",
    "        # Validate required variables\n",
    "        if not all([api_key, endpoint, deployment_name]):\n",
    "            missing = [\n",
    "                var\n",
    "                for var, val in {\n",
    "                    \"AZURE_OPENAI_API_KEY\": api_key,\n",
    "                    \"AZURE_OPENAI_ENDPOINT\": endpoint,\n",
    "                    \"AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME\": deployment_name,\n",
    "                }.items()\n",
    "                if not val\n",
    "            ]\n",
    "            raise ValueError(\n",
    "                f\"Missing required environment variables: {', '.join(missing)}\"\n",
    "            )\n",
    "\n",
    "        return cls(\n",
    "            api_key=api_key,\n",
    "            endpoint=endpoint,\n",
    "            deployment_name=deployment_name,\n",
    "            api_version=api_version,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## File Management\n",
    " \n",
    " Set up utilities to manage resume files and their paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filepath_for_filename(filename: str) -> str:\n",
    "    \"\"\"Get the full path for a given filename.\"\"\"\n",
    "    base_directory = Path.cwd() / \"resumes\"\n",
    "    base_directory.mkdir(exist_ok=True)\n",
    "    return str(base_directory / filename)\n",
    "\n",
    "# Sample resume data\n",
    "sample_resumes = {\n",
    "    \"john_doe.txt\": \"\"\"\n",
    "    John Doe\n",
    "    Senior Software Engineer\n",
    "\n",
    "    Experience:\n",
    "    - Lead Developer at TechCorp (2019-Present)\n",
    "      * Led team of 5 developers on cloud migration project\n",
    "      * Implemented MLOps pipeline reducing deployment time by 60%\n",
    "      * Mentored junior developers and conducted code reviews\n",
    "    \n",
    "    - Senior Software Engineer at InnovSoft (2016-2019)\n",
    "      * Developed machine learning models for predictive maintenance\n",
    "      * Architected microservices infrastructure using Kubernetes\n",
    "      * Improved system performance by 40%\n",
    "\n",
    "    Skills:\n",
    "    - Programming: Python, Java, Go\n",
    "    - Cloud & DevOps: Kubernetes, Docker, AWS\n",
    "    - Machine Learning: TensorFlow, PyTorch, MLOps\n",
    "    - Leadership: Team Management, Mentoring\n",
    "    \n",
    "    Education:\n",
    "    - M.S. Computer Science, Tech University (2016)\n",
    "    - B.S. Computer Science, State University (2014)\n",
    "    \"\"\",\n",
    "    \n",
    "    \"jane_smith.txt\": \"\"\"\n",
    "    Jane Smith\n",
    "    AI Research Engineer\n",
    "\n",
    "    Experience:\n",
    "    - AI Research Lead at DataMinds (2020-Present)\n",
    "      * Published 3 papers on NLP architectures\n",
    "      * Developed novel attention mechanism improving accuracy by 25%\n",
    "      * Led research team of 3 PhD candidates\n",
    "    \n",
    "    - ML Engineer at AITech (2018-2020)\n",
    "      * Implemented computer vision models for autonomous systems\n",
    "      * Reduced model inference time by 35%\n",
    "      * Collaborated with cross-functional teams\n",
    "\n",
    "    Skills:\n",
    "    - Deep Learning: PyTorch, TensorFlow\n",
    "    - NLP: Transformers, BERT, GPT\n",
    "    - Research: Paper Writing, Experimentation\n",
    "    - Languages: Python, C++\n",
    "    \n",
    "    Education:\n",
    "    - PhD in Machine Learning, Tech Institute (2020)\n",
    "    - M.S. AI, Data University (2018)\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "# Save resumes to files\n",
    "resume_files = []\n",
    "for filename, content in sample_resumes.items():\n",
    "    filepath = get_filepath_for_filename(filename)\n",
    "    Path(filepath).write_text(content, encoding='utf-8')\n",
    "    resume_files.append(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Initialize Assistant\n",
    " \n",
    " Create an Azure Assistant Agent with file search capability enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_hr_assistant() -> AzureAssistantAgent:\n",
    "    \"\"\"Create and configure the HR Assistant.\"\"\"\n",
    "    try:\n",
    "        config = AzureConfig.from_env()\n",
    "        kernel = Kernel()\n",
    "\n",
    "        print(f\"Initializing Assistant with:\")\n",
    "        print(f\"- Deployment: {config.deployment_name}\")\n",
    "        print(f\"- Endpoint: {config.endpoint}\")\n",
    "        print(f\"- API Version: {config.api_version}\")\n",
    "\n",
    "        # Get file paths for resumes\n",
    "        resume_paths = [get_filepath_for_filename(f) for f in resume_files]\n",
    "        print(f\"- Resume files: {resume_paths}\")\n",
    "\n",
    "        # Create the assistant with required configuration\n",
    "        agent = await AzureAssistantAgent.create(\n",
    "            kernel=kernel,\n",
    "            deployment_name=config.deployment_name,\n",
    "            endpoint=config.endpoint,\n",
    "            api_key=config.api_key,\n",
    "            api_version=config.api_version,\n",
    "            name=\"HR_Resume_Analyzer\",\n",
    "            instructions=\"\"\"\n",
    "            You are an expert HR assistant specialized in analyzing resumes and providing \n",
    "            detailed candidate evaluations.\n",
    "            \n",
    "            Guidelines:\n",
    "            1. Always analyze the resumes in the document store for your answers\n",
    "            2. Provide specific evidence and quotes from the resumes\n",
    "            3. Format responses using markdown for better readability\n",
    "            4. Compare candidates objectively based on their documented experience\n",
    "            5. Highlight quantifiable achievements and metrics\n",
    "            6. Include relevant education and certification details\n",
    "            \"\"\",\n",
    "            enable_file_search=True,\n",
    "            vector_store_filenames=resume_paths,\n",
    "            ai_model_id=config.deployment_name,  # Required parameter\n",
    "            metadata={\n",
    "                \"type\": \"hr_assistant\",\n",
    "                \"version\": \"1.0\",\n",
    "                \"capabilities\": \"resume_analysis,candidate_comparison\",\n",
    "            },\n",
    "            temperature=0.7,\n",
    "            top_p=0.95,\n",
    "        )\n",
    "\n",
    "        return agent\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating assistant: {str(e)}\")\n",
    "        print(f\"Full exception details: {type(e).__name__}: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Query Interface\n",
    " \n",
    " Create an interface to interact with the assistant and handle responses with citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def analyze_resumes():\n",
    "    \"\"\"Main function to interact with the HR Assistant.\"\"\"\n",
    "    print(\"Initializing HR Assistant...\")\n",
    "    agent = await create_hr_assistant()\n",
    "    \n",
    "    print(\"Creating conversation thread...\")\n",
    "    thread_id = await agent.create_thread()\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            user_input = input(\"\\nEnter your question (or 'exit' to quit): \")\n",
    "            if not user_input or user_input.lower() == \"exit\":\n",
    "                break\n",
    "            \n",
    "            await agent.add_chat_message(\n",
    "                thread_id=thread_id,\n",
    "                message=ChatMessageContent(\n",
    "                    role=AuthorRole.USER,\n",
    "                    content=user_input\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            print(\"\\nAnalyzing resumes...\\n\")\n",
    "            footnotes: List[StreamingAnnotationContent] = []\n",
    "            \n",
    "            async for response in agent.invoke_stream(thread_id=thread_id):\n",
    "                footnotes.extend([\n",
    "                    item for item in response.items \n",
    "                    if isinstance(item, StreamingAnnotationContent)\n",
    "                ])\n",
    "                print(response.content, end=\"\", flush=True)\n",
    "            \n",
    "            if footnotes:\n",
    "                print(\"\\n\\nCitations:\")\n",
    "                for note in footnotes:\n",
    "                    print(f\"\\nâ€¢ From {note.file_id}:\")\n",
    "                    print(f'  \"{note.quote}\"')\n",
    "    \n",
    "    finally:\n",
    "        print(\"\\nCleaning up resources...\")\n",
    "        if agent:\n",
    "            for file_id in agent.file_search_file_ids:\n",
    "                await agent.delete_file(file_id)\n",
    "            await agent.delete_thread(thread_id)\n",
    "            await agent.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Run the Analysis\n",
    " \n",
    " Execute the resume analysis interface. You can run this cell multiple times to start\n",
    " new analysis sessions.\n",
    "\n",
    " Example questions to try:\n",
    " - \"Compare the machine learning experience of both candidates\"\n",
    " - \"Who has more leadership experience and what evidence supports this?\"\n",
    " - \"Create a table comparing the educational backgrounds\"\n",
    " - \"What are their most significant quantifiable achievements?\"\n",
    " - \"Which candidate has more research experience?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing HR Assistant...\n",
      "Initializing Assistant with:\n",
      "- Deployment: gpt-4o-mini\n",
      "- Endpoint: https://fsunavala-openai-eus.openai.azure.com/\n",
      "- API Version: 2024-10-01-preview\n",
      "- Resume files: ['c:\\\\Dev\\\\azure-ai-search-python-playground\\\\resumes\\\\john_doe.txt', 'c:\\\\Dev\\\\azure-ai-search-python-playground\\\\resumes\\\\jane_smith.txt']\n",
      "Error creating assistant: Error code: 400 - {'error': {'message': \"Invalid type for 'metadata.capabilities': expected a string, but got an array instead.\", 'type': 'invalid_request_error', 'param': 'metadata.capabilities', 'code': 'invalid_type'}}\n",
      "Full exception details: BadRequestError: Error code: 400 - {'error': {'message': \"Invalid type for 'metadata.capabilities': expected a string, but got an array instead.\", 'type': 'invalid_request_error', 'param': 'metadata.capabilities', 'code': 'invalid_type'}}\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Invalid type for 'metadata.capabilities': expected a string, but got an array instead.\", 'type': 'invalid_request_error', 'param': 'metadata.capabilities', 'code': 'invalid_type'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m analyze_resumes()\n",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m, in \u001b[0;36manalyze_resumes\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Main function to interact with the HR Assistant.\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitializing HR Assistant...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m create_hr_assistant()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating conversation thread...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m thread_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m agent\u001b[38;5;241m.\u001b[39mcreate_thread()\n",
      "Cell \u001b[1;32mIn[4], line 17\u001b[0m, in \u001b[0;36mcreate_hr_assistant\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- Resume files: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresume_paths\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Create the assistant with required configuration\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     agent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m AzureAssistantAgent\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     18\u001b[0m         kernel\u001b[38;5;241m=\u001b[39mkernel,\n\u001b[0;32m     19\u001b[0m         deployment_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdeployment_name,\n\u001b[0;32m     20\u001b[0m         endpoint\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mendpoint,\n\u001b[0;32m     21\u001b[0m         api_key\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mapi_key,\n\u001b[0;32m     22\u001b[0m         api_version\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mapi_version,\n\u001b[0;32m     23\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHR_Resume_Analyzer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     24\u001b[0m         instructions\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124m        You are an expert HR assistant specialized in analyzing resumes and providing \u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124m        detailed candidate evaluations.\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124m        \u001b[39m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124m        Guidelines:\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124m        1. Always analyze the resumes in the document store for your answers\u001b[39m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124m        2. Provide specific evidence and quotes from the resumes\u001b[39m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124m        3. Format responses using markdown for better readability\u001b[39m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124m        4. Compare candidates objectively based on their documented experience\u001b[39m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124m        5. Highlight quantifiable achievements and metrics\u001b[39m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124m        6. Include relevant education and certification details\u001b[39m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m,\n\u001b[0;32m     36\u001b[0m         enable_file_search\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     37\u001b[0m         vector_store_filenames\u001b[38;5;241m=\u001b[39mresume_paths,\n\u001b[0;32m     38\u001b[0m         ai_model_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdeployment_name,  \u001b[38;5;66;03m# Required parameter\u001b[39;00m\n\u001b[0;32m     39\u001b[0m         metadata\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhr_assistant\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     41\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     42\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapabilities\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume_analysis\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcandidate_comparison\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     43\u001b[0m         },\n\u001b[0;32m     44\u001b[0m         temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[0;32m     45\u001b[0m         top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.95\u001b[39m\n\u001b[0;32m     46\u001b[0m     )\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m agent\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-search-python-playground\\.venv\\Lib\\site-packages\\semantic_kernel\\agents\\open_ai\\azure_assistant_agent.py:322\u001b[0m, in \u001b[0;36mAzureAssistantAgent.create\u001b[1;34m(cls, kernel, service_id, deployment_name, api_key, endpoint, api_version, ad_token, ad_token_provider, client, default_headers, env_file_path, env_file_encoding, description, id, instructions, name, enable_code_interpreter, code_interpreter_filenames, code_interpreter_file_ids, enable_file_search, vector_store_filenames, vector_store_file_ids, enable_json_response, temperature, top_p, vector_store_id, metadata, max_completion_tokens, max_prompt_tokens, parallel_tool_calls_enabled, truncation_message_count, **kwargs)\u001b[0m\n\u001b[0;32m    319\u001b[0m         agent\u001b[38;5;241m.\u001b[39mvector_store_id \u001b[38;5;241m=\u001b[39m vector_store_id\n\u001b[0;32m    320\u001b[0m         assistant_create_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvector_store_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m vector_store_id\n\u001b[1;32m--> 322\u001b[0m agent\u001b[38;5;241m.\u001b[39massistant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m agent\u001b[38;5;241m.\u001b[39mcreate_assistant(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39massistant_create_kwargs)\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m agent\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-search-python-playground\\.venv\\Lib\\site-packages\\semantic_kernel\\agents\\open_ai\\open_ai_assistant_base.py:298\u001b[0m, in \u001b[0;36mOpenAIAssistantBase.create_assistant\u001b[1;34m(self, ai_model_id, description, instructions, name, enable_code_interpreter, code_interpreter_file_ids, enable_file_search, vector_store_id, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    295\u001b[0m         create_assistant_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options_metadata_key] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    296\u001b[0m     create_assistant_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options_metadata_key] \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(execution_settings)\n\u001b[1;32m--> 298\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massistant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39massistants\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcreate_assistant_kwargs,\n\u001b[0;32m    300\u001b[0m )\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_deleted:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_deleted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-search-python-playground\\.venv\\Lib\\site-packages\\openai\\resources\\beta\\assistants.py:532\u001b[0m, in \u001b[0;36mAsyncAssistants.create\u001b[1;34m(self, model, description, instructions, metadata, name, response_format, temperature, tool_resources, tools, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;124;03mCreate an assistant with a model and instructions.\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;124;03m  timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    531\u001b[0m extra_headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI-Beta\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistants=v2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[1;32m--> 532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/assistants\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    534\u001b[0m     body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[0;32m    535\u001b[0m         {\n\u001b[0;32m    536\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    537\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m: description,\n\u001b[0;32m    538\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstructions\u001b[39m\u001b[38;5;124m\"\u001b[39m: instructions,\n\u001b[0;32m    539\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: name,\n\u001b[0;32m    541\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m    542\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m    543\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_resources\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_resources,\n\u001b[0;32m    544\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m    545\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m    546\u001b[0m         },\n\u001b[0;32m    547\u001b[0m         assistant_create_params\u001b[38;5;241m.\u001b[39mAssistantCreateParams,\n\u001b[0;32m    548\u001b[0m     ),\n\u001b[0;32m    549\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    550\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    551\u001b[0m     ),\n\u001b[0;32m    552\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mAssistant,\n\u001b[0;32m    553\u001b[0m )\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-search-python-playground\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1816\u001b[0m, in \u001b[0;36mAsyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1802\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1803\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1804\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1811\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1812\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _AsyncStreamT:\n\u001b[0;32m   1813\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1814\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1815\u001b[0m     )\n\u001b[1;32m-> 1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls)\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-search-python-playground\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1510\u001b[0m, in \u001b[0;36mAsyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m   1502\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1503\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1508\u001b[0m     remaining_retries: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1509\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _AsyncStreamT:\n\u001b[1;32m-> 1510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1511\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1512\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1513\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1514\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1515\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries,\n\u001b[0;32m   1516\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-search-python-playground\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1611\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[1;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[0;32m   1608\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39maread()\n\u001b[0;32m   1610\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1611\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1613\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1614\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1615\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1619\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39mget_max_retries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries) \u001b[38;5;241m-\u001b[39m retries,\n\u001b[0;32m   1620\u001b[0m )\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"Invalid type for 'metadata.capabilities': expected a string, but got an array instead.\", 'type': 'invalid_request_error', 'param': 'metadata.capabilities', 'code': 'invalid_type'}}"
     ]
    }
   ],
   "source": [
    "await analyze_resumes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
