{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install llama-index==11.6\n",
    "! pip install python-dotenv==1.0.1\n",
    "! pip install llama-index-vector-stores-azureaisearch==0.2.1\n",
    "! pip install azure-search-documents==11.5.1\n",
    "! pip install llama-index-embeddings-azure-openai==0.2.5\n",
    "! pip install llama-index-llms-azure-openai==0.2.1\n",
    "! pip install nest_asyncio==1.6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initial Setup\n",
    "First, we set up the environment, load the necessary credentials, and initialize the Azure OpenAI and Azure AI Search services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initial Setup: Load environment variables and initialize services\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from llama_index.core import StorageContext, VectorStoreIndex\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.vector_stores.azureaisearch import AzureAISearchVectorStore, IndexManagement\n",
    "from llama_index.core.settings import Settings\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Environment Variables\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME = os.getenv(\"AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME\")\n",
    "AZURE_OPENAI_EMBEDDING_DEPLOYED_MODEL_NAME = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYED_MODEL_NAME\")\n",
    "SEARCH_SERVICE_ENDPOINT = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "SEARCH_SERVICE_API_KEY = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "INDEX_NAME = \"llamaindex-property-graph\"\n",
    "\n",
    "# Initialize Azure OpenAI models\n",
    "llm = AzureOpenAI(\n",
    "    model=AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME,\n",
    "    deployment_name=AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_version=\"2024-02-01\"\n",
    ")\n",
    "\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model=AZURE_OPENAI_EMBEDDING_DEPLOYED_MODEL_NAME,\n",
    "    deployment_name=AZURE_OPENAI_EMBEDDING_DEPLOYED_MODEL_NAME,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_version=\"2024-02-01\"\n",
    ")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "# Initialize search clients\n",
    "credential = AzureKeyCredential(SEARCH_SERVICE_API_KEY)\n",
    "index_client = SearchIndexClient(endpoint=SEARCH_SERVICE_ENDPOINT, credential=credential)\n",
    "search_client = SearchClient(endpoint=SEARCH_SERVICE_ENDPOINT, index_name=INDEX_NAME, credential=credential)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Documents\n",
    "Next, load the documents (in this case, the \"state_of_the_union.txt\" file) that we will use to generate the property graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Documents\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# Load documents from the text file\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"data/txt/state_of_the_union.txt\"],\n",
    ").load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Property Graph Construction (Default Mode)\n",
    "We now initialize the `AzureAISearchVectorStore` to persist vectors in Azure AI Search and build the property graph using the default implicit method for extracting entities and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subtype value aml has no mapping, use base class VectorSearchVectorizer.\n",
      "Subtype value aml has no mapping, use base class VectorSearchVectorizer.\n",
      "Subtype value aml has no mapping, use base class VectorSearchVectorizer.\n"
     ]
    }
   ],
   "source": [
    "# Property Graph Construction: Implicit Extraction Method\n",
    "from llama_index.core.indices.property_graph import ImplicitPathExtractor\n",
    "import nest_asyncio\n",
    "from llama_index.core import PropertyGraphIndex\n",
    "\n",
    "# Apply nest_asyncio to avoid runtime errors in async environments\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Initialize Azure AI Search vector store\n",
    "vector_store = AzureAISearchVectorStore(\n",
    "    search_or_index_client=index_client,\n",
    "    index_name=INDEX_NAME,\n",
    "    index_management=IndexManagement.CREATE_IF_NOT_EXISTS,\n",
    "    id_field_key=\"id\",\n",
    "    chunk_field_key=\"text\",\n",
    "    embedding_field_key=\"embedding\",\n",
    "    embedding_dimensionality=1536,  # Adjust to match embedding model output (like ada-002)\n",
    "    metadata_string_field_key=\"metadata\",\n",
    "    doc_id_field_key=\"doc_id\",\n",
    "    language_analyzer=\"en.lucene\",\n",
    "    vector_algorithm_type=\"exhaustiveKnn\",\n",
    "    compression_type=\"binary\"\n",
    ")\n",
    "\n",
    "# # Construct the property graph index with implicit path extraction\n",
    "# index = PropertyGraphIndex.from_documents(\n",
    "#     documents,\n",
    "#     llm=llm,\n",
    "#     embed_model=embed_model,\n",
    "#     vector_store=vector_store,\n",
    "#     show_progress=True,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Schema-Guided Extraction\n",
    "In this step, we define a schema to guide the knowledge graph extraction, specifying allowed entity types and relationships. This provides structure to the graph extraction process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 1/1 [00:00<00:00, 27.42it/s]\n",
      "Extracting paths from text with schema: 100%|██████████| 11/11 [00:43<00:00,  3.93s/it]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.27it/s]\n",
      "Generating embeddings: 100%|██████████| 10/10 [00:00<00:00, 20.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# Schema-Guided Extraction Method\n",
    "from typing import Literal\n",
    "from llama_index.core.indices.property_graph import SchemaLLMPathExtractor\n",
    "\n",
    "# Define the schema for entity types and relationships\n",
    "entities = Literal[\"PERSON\", \"PLACE\", \"THING\"]\n",
    "relations = Literal[\"PART_OF\", \"HAS\", \"IS_A\"]\n",
    "schema = {\n",
    "    \"PERSON\": [\"HAS\", \"IS_A\"],\n",
    "    \"PLACE\": [\"PART_OF\", \"HAS\"],\n",
    "    \"THING\": [\"IS_A\"],\n",
    "}\n",
    "\n",
    "# Initialize the schema-based extractor\n",
    "kg_extractor = SchemaLLMPathExtractor(\n",
    "    llm=llm,\n",
    "    possible_entities=entities,\n",
    "    possible_relations=relations,\n",
    "    kg_validation_schema=schema,\n",
    "    strict=True,  # Disallow extractions outside the schema\n",
    ")\n",
    "\n",
    "# Construct the property graph index using the schema-guided extractor\n",
    "index_schema = PropertyGraphIndex.from_documents(\n",
    "    documents,\n",
    "    kg_extractors=[kg_extractor],\n",
    "    vector_store=vector_store,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Free-Form Extraction\n",
    "Here, we allow the LLM to freely infer the entities and relationships without a pre-defined schema. This method relies on the LLM's contextual understanding of the text to build the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 1/1 [00:00<00:00, 45.99it/s]\n",
      "Extracting paths from text: 100%|██████████| 11/11 [00:04<00:00,  2.65it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:01<00:00,  1.68it/s]\n",
      "Generating embeddings: 100%|██████████| 22/22 [00:01<00:00, 18.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# Free-Form Extraction Method\n",
    "from llama_index.core.indices.property_graph import SimpleLLMPathExtractor\n",
    "\n",
    "# Initialize the free-form extractor\n",
    "kg_extractor_free = SimpleLLMPathExtractor()\n",
    "\n",
    "# Construct the property graph index using free-form extraction\n",
    "index_free_form = PropertyGraphIndex.from_documents(\n",
    "    documents,\n",
    "    kg_extractors=[kg_extractor_free],\n",
    "    vector_store=vector_store,\n",
    "    show_progress=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "PropertyGraphIndex.as_retriever() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 13\u001b[0m\n\u001b[0;32m      5\u001b[0m vector_retriever \u001b[38;5;241m=\u001b[39m VectorContextRetriever(\n\u001b[0;32m      6\u001b[0m     index\u001b[38;5;241m.\u001b[39mproperty_graph_store,\n\u001b[0;32m      7\u001b[0m     vector_store\u001b[38;5;241m=\u001b[39mvector_store,\n\u001b[0;32m      8\u001b[0m     embed_model\u001b[38;5;241m=\u001b[39membed_model,\n\u001b[0;32m      9\u001b[0m     similarity_top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# Retrieve top 3 similar nodes\u001b[39;00m\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Retrieve nodes based on a query\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m retriever \u001b[38;5;241m=\u001b[39m \u001b[43mPropertyGraphIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_retriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_retrievers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mvector_retriever\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m results \u001b[38;5;241m=\u001b[39m retriever\u001b[38;5;241m.\u001b[39mretrieve(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDemocracy in the United States\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Display results\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: PropertyGraphIndex.as_retriever() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "# Querying the Property Graph: Keyword and Vector Similarity\n",
    "from llama_index.core.indices.property_graph import VectorContextRetriever\n",
    "\n",
    "# Initialize a vector context retriever\n",
    "vector_retriever = VectorContextRetriever(\n",
    "    index.property_graph_store,\n",
    "    vector_store=vector_store,\n",
    "    embed_model=embed_model,\n",
    "    similarity_top_k=3  # Retrieve top 3 similar nodes\n",
    ")\n",
    "\n",
    "# Retrieve nodes based on a query\n",
    "retriever = PropertyGraphIndex.as_retriever(sub_retrievers=[vector_retriever])\n",
    "results = retriever.retrieve(\"Democracy in the United States\")\n",
    "\n",
    "# Display results\n",
    "for result in results:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Free-Form Extraction\n",
    "Here, we allow the LLM to freely infer the entities and relationships without a pre-defined schema. This method relies on the LLM's contextual understanding of the text to build the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 1/1 [00:00<00:00, 34.42it/s]\n",
      "Extracting paths from text: 100%|██████████| 11/11 [00:07<00:00,  1.46it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.59it/s]\n",
      "Generating embeddings: 100%|██████████| 29/29 [00:01<00:00, 23.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# Free-Form Extraction Method\n",
    "from llama_index.core.indices.property_graph import SimpleLLMPathExtractor\n",
    "\n",
    "# Initialize the free-form extractor\n",
    "kg_extractor_free = SimpleLLMPathExtractor(llm=llm)\n",
    "\n",
    "# Construct the property graph index using free-form extraction\n",
    "index_free_form = PropertyGraphIndex.from_documents(\n",
    "    documents,\n",
    "    kg_extractors=[kg_extractor_free],\n",
    "    vector_store=vector_store,\n",
    "    show_progress=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Query the Property Graph\n",
    "We can now query the property graph using both keyword-based and vector similarity-based methods. Here, we demonstrate how to search using vector embeddings stored in Azure AI Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'search'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m retriever \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mas_retriever(sub_retrievers\u001b[38;5;241m=\u001b[39m[vector_retriever])\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Retrieve nodes based on a query\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDemocracy in the United States\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Display results\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-search-python-playground\\venv\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:265\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    258\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[0;32m    259\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    262\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    263\u001b[0m )\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 265\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-search-python-playground\\venv\\Lib\\site-packages\\llama_index\\core\\base\\base_retriever.py:245\u001b[0m, in \u001b[0;36mBaseRetriever.retrieve\u001b[1;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mas_trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    242\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mRETRIEVE,\n\u001b[0;32m    243\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query_bundle\u001b[38;5;241m.\u001b[39mquery_str},\n\u001b[0;32m    244\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m retrieve_event:\n\u001b[1;32m--> 245\u001b[0m         nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    246\u001b[0m         nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_recursive_retrieval(query_bundle, nodes)\n\u001b[0;32m    247\u001b[0m         retrieve_event\u001b[38;5;241m.\u001b[39mon_end(\n\u001b[0;32m    248\u001b[0m             payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mNODES: nodes},\n\u001b[0;32m    249\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-search-python-playground\\venv\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:265\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    258\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[0;32m    259\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    262\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    263\u001b[0m )\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 265\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-search-python-playground\\venv\\Lib\\site-packages\\llama_index\\core\\indices\\property_graph\\retriever.py:52\u001b[0m, in \u001b[0;36mPGRetriever._retrieve\u001b[1;34m(self, query_bundle)\u001b[0m\n\u001b[0;32m     50\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_async:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sub_retriever \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msub_retrievers, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_progress):\n\u001b[0;32m     55\u001b[0m     results\u001b[38;5;241m.\u001b[39mextend(sub_retriever\u001b[38;5;241m.\u001b[39mretrieve(query_bundle))\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-search-python-playground\\venv\\Lib\\site-packages\\llama_index\\core\\async_utils.py:33\u001b[0m, in \u001b[0;36masyncio_run\u001b[1;34m(coro)\u001b[0m\n\u001b[0;32m     30\u001b[0m     loop \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mget_event_loop()\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# If we're here, there's an existing loop but it's not running\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoro\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# If we can't get the event loop, we're likely in a different thread, or its already running\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-search-python-playground\\venv\\Lib\\site-packages\\nest_asyncio.py:98\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\futures.py:203\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\tasks.py:279\u001b[0m, in \u001b[0;36mTask.__step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    277\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 279\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_must_cancel:\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-search-python-playground\\venv\\Lib\\site-packages\\llama_index\\core\\indices\\property_graph\\retriever.py:64\u001b[0m, in \u001b[0;36mPGRetriever._aretrieve\u001b[1;34m(self, query_bundle)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sub_retriever \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msub_retrievers:\n\u001b[0;32m     62\u001b[0m     tasks\u001b[38;5;241m.\u001b[39mappend(sub_retriever\u001b[38;5;241m.\u001b[39maretrieve(query_bundle))\n\u001b[1;32m---> 64\u001b[0m async_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m run_jobs(\n\u001b[0;32m     65\u001b[0m     tasks, workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_workers, show_progress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_progress\n\u001b[0;32m     66\u001b[0m )\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# flatten the results\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deduplicate([node \u001b[38;5;28;01mfor\u001b[39;00m nodes \u001b[38;5;129;01min\u001b[39;00m async_results \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes])\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-search-python-playground\\venv\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:297\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.async_wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    290\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[0;32m    291\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    294\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    295\u001b[0m )\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 297\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-search-python-playground\\venv\\Lib\\site-packages\\llama_index\\core\\async_utils.py:148\u001b[0m, in \u001b[0;36mrun_jobs\u001b[1;34m(jobs, show_progress, workers, desc)\u001b[0m\n\u001b[0;32m    146\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m tqdm_asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mpool_jobs, desc\u001b[38;5;241m=\u001b[39mdesc)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 148\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mpool_jobs)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\tasks.py:349\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 349\u001b[0m         \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    351\u001b[0m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[0;32m    352\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\tasks.py:277\u001b[0m, in \u001b[0;36mTask.__step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-search-python-playground\\venv\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:297\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.async_wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    290\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[0;32m    291\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    294\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    295\u001b[0m )\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 297\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-search-python-playground\\venv\\Lib\\site-packages\\llama_index\\core\\async_utils.py:139\u001b[0m, in \u001b[0;36mrun_jobs.<locals>.worker\u001b[1;34m(job)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;129m@dispatcher\u001b[39m\u001b[38;5;241m.\u001b[39mspan\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mworker\u001b[39m(job: Coroutine) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m semaphore:\n\u001b[1;32m--> 139\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m job\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-search-python-playground\\venv\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:297\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.async_wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    290\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[0;32m    291\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    294\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    295\u001b[0m )\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 297\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-search-python-playground\\venv\\Lib\\site-packages\\llama_index\\core\\base\\base_retriever.py:276\u001b[0m, in \u001b[0;36mBaseRetriever.aretrieve\u001b[1;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mas_trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    273\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mRETRIEVE,\n\u001b[0;32m    274\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query_bundle\u001b[38;5;241m.\u001b[39mquery_str},\n\u001b[0;32m    275\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m retrieve_event:\n\u001b[1;32m--> 276\u001b[0m         nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aretrieve(query_bundle\u001b[38;5;241m=\u001b[39mquery_bundle)\n\u001b[0;32m    277\u001b[0m         nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ahandle_recursive_retrieval(\n\u001b[0;32m    278\u001b[0m             query_bundle\u001b[38;5;241m=\u001b[39mquery_bundle, nodes\u001b[38;5;241m=\u001b[39mnodes\n\u001b[0;32m    279\u001b[0m         )\n\u001b[0;32m    280\u001b[0m         retrieve_event\u001b[38;5;241m.\u001b[39mon_end(\n\u001b[0;32m    281\u001b[0m             payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mNODES: nodes},\n\u001b[0;32m    282\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-search-python-playground\\venv\\Lib\\site-packages\\llama_index\\core\\indices\\property_graph\\sub_retrievers\\base.py:143\u001b[0m, in \u001b[0;36mBasePGRetriever._aretrieve\u001b[1;34m(self, query_bundle)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_aretrieve\u001b[39m(\u001b[38;5;28mself\u001b[39m, query_bundle: QueryBundle) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[NodeWithScore]:\n\u001b[1;32m--> 143\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maretrieve_from_graph(query_bundle)\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_text:\n\u001b[0;32m    145\u001b[0m         nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_add_source_text(nodes)\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-search-python-playground\\venv\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:297\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.async_wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    290\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[0;32m    291\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    294\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    295\u001b[0m )\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 297\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-search-python-playground\\venv\\Lib\\site-packages\\llama_index\\core\\indices\\property_graph\\sub_retrievers\\vector.py:179\u001b[0m, in \u001b[0;36mVectorContextRetriever.aretrieve_from_graph\u001b[1;34m(self, query_bundle)\u001b[0m\n\u001b[0;32m    174\u001b[0m     triplets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_store\u001b[38;5;241m.\u001b[39maget_rel_map(\n\u001b[0;32m    175\u001b[0m         kg_nodes, depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path_depth, ignore_rels\u001b[38;5;241m=\u001b[39m[KG_SOURCE_REL]\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_store \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m     query_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_store\u001b[38;5;241m.\u001b[39maquery(vector_store_query)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_result\u001b[38;5;241m.\u001b[39mnodes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m query_result\u001b[38;5;241m.\u001b[39msimilarities \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    181\u001b[0m         kg_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_kg_ids(query_result\u001b[38;5;241m.\u001b[39mnodes)\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-search-python-playground\\venv\\Lib\\site-packages\\llama_index\\vector_stores\\azureaisearch\\base.py:1146\u001b[0m, in \u001b[0;36mAzureAISearchVectorStore.aquery\u001b[1;34m(self, query, **kwargs)\u001b[0m\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m VectorStoreQueryMode\u001b[38;5;241m.\u001b[39mSEMANTIC_HYBRID:\n\u001b[0;32m   1143\u001b[0m     azure_query_result_search \u001b[38;5;241m=\u001b[39m AzureQueryResultSearchSemanticHybrid(\n\u001b[0;32m   1144\u001b[0m         query, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_field_mapping, odata_filter, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_async_search_client\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[1;32m-> 1146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m azure_query_result_search\u001b[38;5;241m.\u001b[39masearch()\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-search-python-playground\\venv\\Lib\\site-packages\\llama_index\\vector_stores\\azureaisearch\\base.py:1292\u001b[0m, in \u001b[0;36mAzureQueryResultSearchBase.asearch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1290\u001b[0m search_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_search_query()\n\u001b[0;32m   1291\u001b[0m vectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_query_vector()\n\u001b[1;32m-> 1292\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acreate_query_result(search_query, vectors)\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-search-python-playground\\venv\\Lib\\site-packages\\llama_index\\vector_stores\\azureaisearch\\base.py:1233\u001b[0m, in \u001b[0;36mAzureQueryResultSearchBase._acreate_query_result\u001b[1;34m(self, search_query, vectors)\u001b[0m\n\u001b[0;32m   1230\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acreate_query_result\u001b[39m(\n\u001b[0;32m   1231\u001b[0m     \u001b[38;5;28mself\u001b[39m, search_query: \u001b[38;5;28mstr\u001b[39m, vectors: Optional[List[Any]]\n\u001b[0;32m   1232\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VectorStoreQueryResult:\n\u001b[1;32m-> 1233\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_search_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m(\n\u001b[0;32m   1234\u001b[0m         search_text\u001b[38;5;241m=\u001b[39msearch_query,\n\u001b[0;32m   1235\u001b[0m         vector_queries\u001b[38;5;241m=\u001b[39mvectors,\n\u001b[0;32m   1236\u001b[0m         top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query\u001b[38;5;241m.\u001b[39msimilarity_top_k,\n\u001b[0;32m   1237\u001b[0m         select\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_fields,\n\u001b[0;32m   1238\u001b[0m         \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_odata_filter,\n\u001b[0;32m   1239\u001b[0m     )\n\u001b[0;32m   1241\u001b[0m     id_result \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1242\u001b[0m     node_result \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'search'"
     ]
    }
   ],
   "source": [
    "# Querying the Property Graph: Keyword and Vector Similarity\n",
    "from llama_index.core.indices.property_graph import VectorContextRetriever\n",
    "\n",
    "# Initialize a vector context retriever\n",
    "vector_retriever = VectorContextRetriever(\n",
    "    index.property_graph_store,\n",
    "    vector_store=vector_store,\n",
    "    embed_model=embed_model,\n",
    "    similarity_top_k=3  # Retrieve top 3 similar nodes\n",
    ")\n",
    "\n",
    "# Call `as_retriever()` on the `index` instance, not the class\n",
    "retriever = index.as_retriever(sub_retrievers=[vector_retriever])\n",
    "\n",
    "# Retrieve nodes based on a query\n",
    "results = retriever.retrieve(\"Democracy in the United States\")\n",
    "\n",
    "# Display results\n",
    "for result in results:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Client: <SearchClient [endpoint='https://fsunavala-ai-search.search.windows.net', index='llamaindex-property-graph']>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Search Client: {search_client}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Property Graph Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.property_graph_store.save_networkx_graph(name=\"./kg.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
