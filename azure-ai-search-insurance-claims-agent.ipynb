{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install semantic-kernel==1.17.0 python-dotenv aiofiles nest_asyncio azure-search-documents pyperclip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from semantic_kernel.kernel import Kernel\n",
    "from semantic_kernel.agents import AgentGroupChat, ChatCompletionAgent\n",
    "from semantic_kernel.agents.open_ai.azure_assistant_agent import AzureAssistantAgent\n",
    "from semantic_kernel.agents.strategies.selection.kernel_function_selection_strategy import KernelFunctionSelectionStrategy\n",
    "from semantic_kernel.agents.strategies.termination.kernel_function_termination_strategy import KernelFunctionTerminationStrategy\n",
    "from semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion import AzureChatCompletion\n",
    "from semantic_kernel.contents.chat_message_content import ChatMessageContent\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "from semantic_kernel.functions.kernel_function_from_prompt import KernelFunctionFromPrompt\n",
    "\n",
    "load_dotenv()\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME\")\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-10-01-preview\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Mock CSV Data (Simulated Files)\n",
    "Here, we create local CSV files representing the insurance datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted files:\n",
      "c:\\Dev\\azure-ai-search-python-playground\\insurance_data\\insurance_claims.txt\n",
      "c:\\Dev\\azure-ai-search-python-playground\\insurance_data\\policy_data.txt\n",
      "c:\\Dev\\azure-ai-search-python-playground\\insurance_data\\fraud_rules.txt\n",
      "c:\\Dev\\azure-ai-search-python-playground\\insurance_data\\customer_faq.txt\n",
      "c:\\Dev\\azure-ai-search-python-playground\\insurance_data\\underwriting_guidelines.txt\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path.cwd() / \"insurance_data\"\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Write CSV files\n",
    "insurance_claims_content = \"\"\"months_as_customer,age,policy_number,policy_bind_date,policy_state,policy_csl,policy_deductable,policy_annual_premium,umbrella_limit,insured_zip,insured_sex,insured_education_level,insured_occupation,insured_hobbies,insured_relationship,capital-gains,capital-loss,incident_date,incident_type,collision_type,incident_severity,authorities_contacted,incident_state,incident_city,incident_location,incident_hour_of_the_day,number_of_vehicles_involved,property_damage,bodily_injuries,witnesses,police_report_available,total_claim_amount,injury_claim,property_claim,vehicle_claim,auto_make,auto_model,auto_year,fraud_reported\n",
    "328,48,521585,10/17/2014,OH,250/500,1000,1406.91,0,466132,MALE,MD,craft-repair,sleeping,husband,53300,0,1/25/2015,Single Vehicle Collision,Side Collision,Major Damage,Police,SC,Columbus,9935 4th Drive,5,1,YES,1,2,YES,71610,6510,13020,52080,Saab,92x,2004,Y\n",
    "228,42,342868,6/27/2006,IN,250/500,2000,1197.22,5000000,468176,MALE,MD,machine-op-inspct,reading,other-relative,0,0,1/21/2015,Vehicle Theft,?,Minor Damage,Police,VA,Riverwood,6608 MLK Hwy,8,1,?,0,0,?,5070,780,780,3510,Mercedes,E400,2007,Y\n",
    "134,29,687698,9/6/2000,OH,100/300,2000,1413.14,5000000,430632,FEMALE,PhD,sales,board-games,own-child,35100,0,2/22/2015,Multi-vehicle Collision,Rear Collision,Minor Damage,Police,NY,Columbus,7121 Francis Lane,7,3,NO,2,3,NO,34650,7700,3850,23100,Dodge,RAM,2007,N\n",
    "256,41,227811,5/25/1990,IL,250/500,2000,1415.74,6000000,608117,FEMALE,PhD,armed-forces,board-games,unmarried,48900,-62400,1/10/2015,Single Vehicle Collision,Front Collision,Major Damage,Police,OH,Arlington,6956 Maple Drive,5,1,?,1,2,NO,63400,6340,6340,50720,Chevrolet,Tahoe,2014,Y\n",
    "\"\"\"\n",
    "\n",
    "(policy_data, fraud_rules, customer_faq, underwriting_guidelines) = (\n",
    "\"\"\"policy_number,policy_state,coverage_type,coverage_limit,deductible,endorsements,flood_coverage,liability_limit,policy_start_date,policy_end_date\n",
    "521585,OH,Homeowner,300000,1000,\"{fire:yes,water:yes}\",no,100000,2014-10-17,2025-10-17\n",
    "342868,IN,Auto,250000,2000,\"{theft:yes}\",no,500000,2006-06-27,2026-06-27\n",
    "687698,OH,Homeowner,350000,2000,\"{fire:yes,water:yes}\",yes,100000,2000-09-06,2030-09-06\n",
    "227811,IL,Homeowner,300000,2000,\"{fire:yes}\",no,100000,1990-05-25,2030-05-25\n",
    "\"\"\",\n",
    "\"\"\"rule_id,pattern_description,trigger_condition,action\n",
    "1,\"Multiple small claims in 6 months\",\"num_small_claims_6mo>2\",\"flag_suspicious\"\n",
    "2,\"Inconsistent incident date vs. report date\",\"date_mismatch==True\",\"request_additional_docs\"\n",
    "3,\"Suspicious theft claims without police report\",\"theft_claim==True AND police_report=='NO'\",\"flag_suspicious\"\n",
    "4,\"Frequent total loss collisions at odd hours\",\"nighttime_collision==True AND total_loss==True\",\"flag_suspicious\"\n",
    "\"\"\",\n",
    "\"\"\"question_id,question_text,answer_text\n",
    "101,\"How do I file a claim?\",\"Log into your BlueSky portal, select 'File a Claim', and follow the steps.\"\n",
    "102,\"Does my homeownerâ€™s policy cover flood damage?\",\"Flood damage requires a separate flood endorsement unless stated otherwise.\"\n",
    "103,\"What documents do I need for a major damage claim?\",\"Professional repair estimates, invoices for replaced items, and if applicable, a police report.\"\n",
    "\"\"\",\n",
    "\"\"\"guideline_id,criterion,threshold_or_condition,required_action\n",
    "U1,\"High-value claims\",\"claim_amount>25000\",\"escalate_to_senior_underwriter\"\n",
    "U2,\"Flood coverage requirement\",\"flood_claim==True AND flood_coverage==False\",\"deny_claim\"\n",
    "U3,\"Require professional estimate\",\"claim_amount>5000\",\"request_professional_estimate\"\n",
    "U4,\"Missing police report on theft\",\"theft_claim==True AND police_report=='NO'\",\"request_additional_docs\"\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "(DATA_DIR / \"insurance_claims.csv\").write_text(insurance_claims_content, encoding='utf-8')\n",
    "(DATA_DIR / \"policy_data.csv\").write_text(policy_data, encoding='utf-8')\n",
    "(DATA_DIR / \"fraud_rules.csv\").write_text(fraud_rules, encoding='utf-8')\n",
    "(DATA_DIR / \"customer_faq.csv\").write_text(customer_faq, encoding='utf-8')\n",
    "(DATA_DIR / \"underwriting_guidelines.csv\").write_text(underwriting_guidelines, encoding='utf-8')\n",
    "\n",
    "vector_filenames = [\n",
    "    str(DATA_DIR / \"insurance_claims.csv\"),\n",
    "    str(DATA_DIR / \"policy_data.csv\"),\n",
    "    str(DATA_DIR / \"fraud_rules.csv\"),\n",
    "    str(DATA_DIR / \"customer_faq.csv\"),\n",
    "    str(DATA_DIR / \"underwriting_guidelines.csv\")\n",
    "]\n",
    "\n",
    "# Convert all CSV files in vector_filenames to TXT\n",
    "converted_filenames = []\n",
    "for filename in vector_filenames:\n",
    "    if filename.lower().endswith(\".csv\"):\n",
    "        txt_filename = filename.replace(\".csv\", \".txt\")\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as csv_file:\n",
    "            content = csv_file.read()\n",
    "        with open(txt_filename, \"w\", encoding=\"utf-8\") as txt_file:\n",
    "            txt_file.write(content)\n",
    "        converted_filenames.append(txt_filename)\n",
    "    else:\n",
    "        # If it's already a supported format (like .txt), just add it\n",
    "        converted_filenames.append(filename)\n",
    "\n",
    "# Now converted_filenames will contain .txt versions instead of .csv\n",
    "# You can use converted_filenames with your agent setup.\n",
    "print(\"Converted files:\")\n",
    "for f in converted_filenames:\n",
    "    print(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "# 2. Kernel & Agent Setup\n",
    "###################################################################\n",
    "def create_kernel():\n",
    "    kernel = Kernel()\n",
    "    kernel.add_service(\n",
    "        AzureChatCompletion(\n",
    "            deployment_name=AZURE_OPENAI_DEPLOYMENT,\n",
    "            endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "            api_key=AZURE_OPENAI_API_KEY,\n",
    "            api_version=AZURE_OPENAI_API_VERSION\n",
    "        )\n",
    "    )\n",
    "    return kernel\n",
    "\n",
    "# Agent Names\n",
    "COORDINATOR_NAME = \"UnderwritingCoordinator\"\n",
    "FILE_SEARCHER_NAME = \"FileSearcher\"\n",
    "DATA_ANALYST_NAME = \"DataAnalyst\"\n",
    "\n",
    "# Coordinator agent: orchestrates underwriting decisions\n",
    "coordinator_kernel = create_kernel()\n",
    "agent_coordinator = ChatCompletionAgent(\n",
    "    service_id=COORDINATOR_NAME,\n",
    "    kernel=coordinator_kernel,\n",
    "    name=COORDINATOR_NAME,\n",
    "    instructions=f\"\"\"\n",
    "        You are a senior Underwriting Coordinator Agent at BlueSky Insurance.\n",
    "        The user will describe claim scenarios and ask for underwriting decisions.\n",
    "        Your tasks:\n",
    "        - Understand the user's request (e.g., assess a new claim, check coverage).\n",
    "        - If you need data from policies, fraud rules, or guidelines, ask {FILE_SEARCHER_NAME}.\n",
    "        - If you need analysis of claims history or fraud predictions, ask {DATA_ANALYST_NAME}.\n",
    "        - After gathering data, provide a coherent underwriting recommendation.\n",
    "        - If done, indicate satisfaction so the conversation ends.\n",
    "    \"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "# 3. File Search Agent Creation (Known Issue: CSV not supported)\n",
    "###################################################################\n",
    "# Here is where the error is triggered: AzureAssistantAgent attempts to create a vector store \n",
    "# from CSV files, which is currently not supported by the API. \n",
    "# To debug:\n",
    "# - Convert CSV files to .txt or another supported format before creating this agent\n",
    "# - Or remove vector_store_filenames and disable file search\n",
    "# Current code will fail with the \"unsupported_file\" error.\n",
    "\n",
    "file_search_kernel = create_kernel()\n",
    "\n",
    "try:\n",
    "    file_search_agent = asyncio.run(AzureAssistantAgent.create(\n",
    "        kernel=file_search_kernel,\n",
    "        service_id=FILE_SEARCHER_NAME,\n",
    "        name=FILE_SEARCHER_NAME,\n",
    "        instructions=\"\"\"\n",
    "            You are a file-search agent. You have access to insurance-related CSV files (claims, policies, rules, FAQs, guidelines).\n",
    "            Retrieve relevant information as requested by the coordinator. Return structured info.\n",
    "        \"\"\",\n",
    "        enable_file_search=True,\n",
    "        vector_store_filenames=converted_filenames,  \n",
    "        ai_model_id=AZURE_OPENAI_DEPLOYMENT,\n",
    "        endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "        api_key=AZURE_OPENAI_API_KEY,\n",
    "        api_version=AZURE_OPENAI_API_VERSION,\n",
    "        deployment_name=AZURE_OPENAI_DEPLOYMENT\n",
    "    ))\n",
    "except Exception as e:\n",
    "    print(\"Error creating file_search_agent:\", e)\n",
    "    # DEBUG NOTE: The error indicates CSV files are not supported. \n",
    "    # To fix: Convert these CSV files to .txt or another supported format.\n",
    "    file_search_agent = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "# 4. Data Analyst Agent Creation\n",
    "###################################################################\n",
    "# The Data Analyst agent uses code interpreter. This one should work if the environment is correct.\n",
    "# But if the file_search_agent creation failed, this code still runs. You can conditionally skip it.\n",
    "\n",
    "data_analyst_kernel = create_kernel()\n",
    "try:\n",
    "    data_analyst_agent = asyncio.run(AzureAssistantAgent.create(\n",
    "        kernel=data_analyst_kernel,\n",
    "        service_id=DATA_ANALYST_NAME,\n",
    "        name=DATA_ANALYST_NAME,\n",
    "        instructions=\"\"\"\n",
    "            You are a data analyst agent with code interpreter capability.\n",
    "            Analyze claims data, check for fraud patterns, summarize claim amounts, etc.\n",
    "            When asked, produce tables, metrics, or suggestions.\n",
    "        \"\"\",\n",
    "        enable_code_interpreter=True,\n",
    "        code_interpreter_filenames=[], # no files attached\n",
    "        ai_model_id=AZURE_OPENAI_DEPLOYMENT,\n",
    "        endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "        api_key=AZURE_OPENAI_API_KEY,\n",
    "        api_version=AZURE_OPENAI_API_VERSION,\n",
    "        deployment_name=AZURE_OPENAI_DEPLOYMENT\n",
    "    ))\n",
    "except Exception as e:\n",
    "    print(\"Error creating data_analyst_agent:\", e)\n",
    "    data_analyst_agent = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group chat created successfully!\n"
     ]
    }
   ],
   "source": [
    "###################################################################\n",
    "# 5. Group Chat Setup\n",
    "###################################################################\n",
    "# Only proceed if both file_search_agent and data_analyst_agent are successfully created.\n",
    "if file_search_agent is not None and data_analyst_agent is not None:\n",
    "    # Selection and Termination Strategies\n",
    "    selection_function = KernelFunctionFromPrompt(\n",
    "        function_name=\"selection\",\n",
    "        prompt=f\"\"\"\n",
    "        Determine which participant takes the next turn.\n",
    "        Participants:\n",
    "        - {COORDINATOR_NAME}\n",
    "        - {FILE_SEARCHER_NAME}\n",
    "        - {DATA_ANALYST_NAME}\n",
    "        - User\n",
    "\n",
    "        Rules:\n",
    "        - After User speaks: {COORDINATOR_NAME} responds.\n",
    "        - {COORDINATOR_NAME} may request {FILE_SEARCHER_NAME} for data or {DATA_ANALYST_NAME} for analysis.\n",
    "        - After {FILE_SEARCHER_NAME} or {DATA_ANALYST_NAME} responds, go back to {COORDINATOR_NAME}.\n",
    "        - Conversation ends when {COORDINATOR_NAME} is satisfied.\n",
    "        History:\n",
    "        {{{{$history}}}}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    termination_keyword = \"done\"\n",
    "    termination_function = KernelFunctionFromPrompt(\n",
    "        function_name=\"termination\",\n",
    "        prompt=f\"\"\"\n",
    "        If {COORDINATOR_NAME} shows a concluding or satisfied remark in the last message, return '{termination_keyword}'.\n",
    "        Otherwise, do not.\n",
    "        Response:\n",
    "        {{{{$history}}}}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    group_chat_kernel = create_kernel()\n",
    "    group_chat = AgentGroupChat(\n",
    "        agents=[agent_coordinator, file_search_agent, data_analyst_agent],\n",
    "        selection_strategy=KernelFunctionSelectionStrategy(\n",
    "            function=selection_function,\n",
    "            kernel=group_chat_kernel,\n",
    "            result_parser=lambda result: str(result.value[0]) if result.value else COORDINATOR_NAME,\n",
    "            agent_variable_name=\"agents\",\n",
    "            history_variable_name=\"history\",\n",
    "        ),\n",
    "        termination_strategy=KernelFunctionTerminationStrategy(\n",
    "            agents=[agent_coordinator],\n",
    "            function=termination_function,\n",
    "            kernel=group_chat_kernel,\n",
    "            result_parser=lambda result: termination_keyword in str(result.value[0]).lower(),\n",
    "            history_variable_name=\"history\",\n",
    "            maximum_iterations=20,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    print(\"Group chat created successfully!\")\n",
    "else:\n",
    "    print(\"Group chat not created due to missing agents (file_search_agent or data_analyst_agent).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Agents and Group Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kernel():\n",
    "    kernel = Kernel()\n",
    "    kernel.add_service(\n",
    "        AzureChatCompletion(\n",
    "            deployment_name=AZURE_OPENAI_DEPLOYMENT,\n",
    "            endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "            api_key=AZURE_OPENAI_API_KEY,\n",
    "            api_version=AZURE_OPENAI_API_VERSION\n",
    "        )\n",
    "    )\n",
    "    return kernel\n",
    "\n",
    "# Agent Names\n",
    "COORDINATOR_NAME = \"UnderwritingCoordinator\"\n",
    "FILE_SEARCHER_NAME = \"FileSearcher\"\n",
    "DATA_ANALYST_NAME = \"DataAnalyst\"\n",
    "\n",
    "# Coordinator agent: orchestrates underwriting decisions\n",
    "coordinator_kernel = create_kernel()\n",
    "agent_coordinator = ChatCompletionAgent(\n",
    "    service_id=COORDINATOR_NAME,\n",
    "    kernel=coordinator_kernel,\n",
    "    name=COORDINATOR_NAME,\n",
    "    instructions=f\"\"\"\n",
    "        You are a senior Underwriting Coordinator Agent at BlueSky Insurance.\n",
    "        The user will describe claim scenarios and ask for underwriting decisions.\n",
    "        Your tasks:\n",
    "        - Understand the user's request (e.g., assess a new claim, check coverage).\n",
    "        - If you need data from policies, fraud rules, or guidelines, ask {FILE_SEARCHER_NAME}.\n",
    "        - If you need analysis of claims history or fraud predictions, ask {DATA_ANALYST_NAME}.\n",
    "        - After gathering data, provide a coherent underwriting recommendation.\n",
    "        - If done, indicate satisfaction so the conversation ends.\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "# File Searcher agent: retrieves info from CSVs\n",
    "file_search_kernel = create_kernel()\n",
    "file_search_agent = asyncio.run(AzureAssistantAgent.create(\n",
    "    kernel=file_search_kernel,\n",
    "    service_id=FILE_SEARCHER_NAME,\n",
    "    name=FILE_SEARCHER_NAME,\n",
    "    instructions=\"\"\"\n",
    "        You are a file-search agent. You have access to insurance-related CSV files (claims, policies, rules, FAQs, guidelines).\n",
    "        Retrieve relevant information as requested by the coordinator. Return structured info.\n",
    "    \"\"\",\n",
    "    enable_file_search=True,\n",
    "    vector_store_filenames=vector_filenames,\n",
    "    ai_model_id=AZURE_OPENAI_DEPLOYMENT,\n",
    "    endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=AZURE_OPENAI_API_VERSION,\n",
    "    deployment_name=AZURE_OPENAI_DEPLOYMENT\n",
    "))\n",
    "\n",
    "# Data Analyst agent: uses code interpreter for analysis\n",
    "data_analyst_kernel = create_kernel()\n",
    "data_analyst_agent = asyncio.run(AzureAssistantAgent.create(\n",
    "    kernel=data_analyst_kernel,\n",
    "    service_id=DATA_ANALYST_NAME,\n",
    "    name=DATA_ANALYST_NAME,\n",
    "    instructions=\"\"\"\n",
    "        You are a data analyst agent with code interpreter capability.\n",
    "        Analyze claims data, check for fraud patterns, summarize claim amounts, etc.\n",
    "        When asked, produce tables, metrics, or suggestions.\n",
    "    \"\"\",\n",
    "    enable_code_interpreter=True,\n",
    "    code_interpreter_filenames=[], # If needed, we can attach CSVs for direct code analysis\n",
    "    ai_model_id=AZURE_OPENAI_DEPLOYMENT,\n",
    "    endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=AZURE_OPENAI_API_VERSION\n",
    "))\n",
    "\n",
    "# Selection and Termination Strategies\n",
    "selection_function = KernelFunctionFromPrompt(\n",
    "    function_name=\"selection\",\n",
    "    prompt=f\"\"\"\n",
    "    Determine which participant takes the next turn.\n",
    "    Participants:\n",
    "    - {COORDINATOR_NAME}\n",
    "    - {FILE_SEARCHER_NAME}\n",
    "    - {DATA_ANALYST_NAME}\n",
    "    - User\n",
    "\n",
    "    Rules:\n",
    "    - After User speaks: {COORDINATOR_NAME} responds.\n",
    "    - {COORDINATOR_NAME} may request {FILE_SEARCHER_NAME} for data or {DATA_ANALYST_NAME} for analysis.\n",
    "    - After {FILE_SEARCHER_NAME} or {DATA_ANALYST_NAME} responds, go back to {COORDINATOR_NAME}.\n",
    "    - Conversation ends when {COORDINATOR_NAME} is satisfied.\n",
    "    History:\n",
    "    {{{{$history}}}}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "termination_keyword = \"done\"\n",
    "termination_function = KernelFunctionFromPrompt(\n",
    "    function_name=\"termination\",\n",
    "    prompt=f\"\"\"\n",
    "    If {COORDINATOR_NAME} shows a concluding or satisfied remark in the last message, return '{termination_keyword}'.\n",
    "    Otherwise, do not.\n",
    "    Response:\n",
    "    {{{{$history}}}}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "group_chat_kernel = create_kernel()\n",
    "group_chat = AgentGroupChat(\n",
    "    agents=[agent_coordinator, file_search_agent, data_analyst_agent],\n",
    "    selection_strategy=KernelFunctionSelectionStrategy(\n",
    "        function=selection_function,\n",
    "        kernel=group_chat_kernel,\n",
    "        result_parser=lambda result: str(result.value[0]) if result.value else COORDINATOR_NAME,\n",
    "        agent_variable_name=\"agents\",\n",
    "        history_variable_name=\"history\",\n",
    "    ),\n",
    "    termination_strategy=KernelFunctionTerminationStrategy(\n",
    "        agents=[agent_coordinator],\n",
    "        function=termination_function,\n",
    "        kernel=group_chat_kernel,\n",
    "        result_parser=lambda result: termination_keyword in str(result.value[0]).lower(),\n",
    "        history_variable_name=\"history\",\n",
    "        maximum_iterations=20,\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask your underwriting questions. Type 'exit' to quit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to select agent: Agent Failure - Strategy unable to select next agent: The next participant to take the turn is the **UnderwritingCoordinator**.\n"
     ]
    },
    {
     "ename": "AgentChatException",
     "evalue": "Failed to select agent",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAgentExecutionException\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Dev\\azure-ai-search-python-playground\\.venv\\Lib\\site-packages\\semantic_kernel\\agents\\group_chat\\agent_group_chat.py:139\u001b[0m, in \u001b[0;36mAgentGroupChat.invoke\u001b[1;34m(self, agent, is_joining)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 139\u001b[0m     selected_agent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselection_strategy\u001b[38;5;241m.\u001b[39mnext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mmessages)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-search-python-playground\\.venv\\Lib\\site-packages\\semantic_kernel\\agents\\strategies\\selection\\kernel_function_selection_strategy.py:98\u001b[0m, in \u001b[0;36mKernelFunctionSelectionStrategy.next\u001b[1;34m(self, agents, history)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m agent_turn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AgentExecutionException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent Failure - Strategy unable to select next agent: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m agent_turn\n",
      "\u001b[1;31mAgentExecutionException\u001b[0m: Agent Failure - Strategy unable to select next agent: The next participant to take the turn is the **UnderwritingCoordinator**.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAgentChatException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 24\u001b[0m\n\u001b[0;32m     20\u001b[0m             is_complete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversation ended.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m chat_loop()\n",
      "Cell \u001b[1;32mIn[29], line 16\u001b[0m, in \u001b[0;36mchat_loop\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m group_chat\u001b[38;5;241m.\u001b[39madd_chat_message(\n\u001b[0;32m     13\u001b[0m     ChatMessageContent(role\u001b[38;5;241m=\u001b[39mAuthorRole\u001b[38;5;241m.\u001b[39mUSER, content\u001b[38;5;241m=\u001b[39muser_input)\n\u001b[0;32m     14\u001b[0m )\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m group_chat\u001b[38;5;241m.\u001b[39minvoke():\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mrole\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mname\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m group_chat\u001b[38;5;241m.\u001b[39mis_complete:\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-search-python-playground\\.venv\\Lib\\site-packages\\semantic_kernel\\agents\\group_chat\\agent_group_chat.py:142\u001b[0m, in \u001b[0;36mAgentGroupChat.invoke\u001b[1;34m(self, agent, is_joining)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m    141\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to select agent: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AgentChatException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to select agent\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39minvoke_agent(selected_agent):\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m message\u001b[38;5;241m.\u001b[39mrole \u001b[38;5;241m==\u001b[39m AuthorRole\u001b[38;5;241m.\u001b[39mASSISTANT:\n",
      "\u001b[1;31mAgentChatException\u001b[0m: Failed to select agent"
     ]
    }
   ],
   "source": [
    "async def chat_loop():\n",
    "    print(\"Ask your underwriting questions. Type 'exit' to quit.\")\n",
    "    is_complete = False\n",
    "    while not is_complete:\n",
    "        user_input = input(\"User:> \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            break\n",
    "\n",
    "        if not user_input.strip():\n",
    "            continue\n",
    "\n",
    "        await group_chat.add_chat_message(\n",
    "            ChatMessageContent(role=AuthorRole.USER, content=user_input)\n",
    "        )\n",
    "\n",
    "        async for response in group_chat.invoke():\n",
    "            print(f\"# {response.role} - {response.name or '*'}: '{response.content}'\")\n",
    "\n",
    "        if group_chat.is_complete:\n",
    "            is_complete = True\n",
    "\n",
    "    print(\"Conversation ended.\")\n",
    "\n",
    "await chat_loop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
